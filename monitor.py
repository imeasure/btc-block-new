import requests
import json
import os
import time
from datetime import datetime, timedelta, timezone

LATEST_FILE = "data.json"
ARCHIVE_DIR = "archive"
KEEP_LATEST_COUNT = 1000

def get_beijing_time():
    tz_bj = timezone(timedelta(hours=8))
    return datetime.now(tz_bj)

def get_latest_height():
    try:
        resp = requests.get("https://blockchain.info/latestblock", timeout=10)
        return resp.json()['height']
    except Exception as e:
        print(f"è·å–æœ€æ–°é«˜åº¦å¤±è´¥: {e}")
        return None

def get_block_details(block_hash):
    """è·å–åŒºå—è¯¦æƒ…ï¼Œå¹¶æå–ã€åŒºå—å¥–åŠ±ã€‘å’Œã€æ€»äº¤æ˜“é‡ã€‘"""
    url = f"https://blockchain.info/rawblock/{block_hash}"
    try:
        resp = requests.get(url, timeout=30).json()
        block_time = resp.get('time', int(time.time()))
        
        all_txs = []
        block_reward = 0
        total_volume = 0
        
        for i, tx in enumerate(resp['tx']):
            # è®¡ç®—å•ç¬”äº¤æ˜“çš„æ€»è¾“å‡º
            tx_value = sum(out.get('value', 0) for out in tx.get('out', [])) / 100000000
            
            # ç¬¬0ç¬”äº¤æ˜“æ°¸è¿œæ˜¯çŸ¿å·¥çš„ Coinbase äº¤æ˜“ (åŒºå—å¥–åŠ± + æ‰‹ç»­è´¹)
            if i == 0:
                block_reward = tx_value
            
            total_volume += tx_value
            all_txs.append({"txid": tx.get('hash', ''), "value": tx_value})
            
        all_txs.sort(key=lambda x: x['value'], reverse=True)
        
        return all_txs[:3], block_time, block_reward, total_volume
    except Exception as e:
        print(f"è§£æå¤±è´¥: {e}")
        return [], int(time.time()), 0, 0

def save_to_archive(new_blocks):
    if not os.path.exists(ARCHIVE_DIR):
        os.makedirs(ARCHIVE_DIR)
    grouped_data = {}
    for block in new_blocks:
        dt = datetime.fromtimestamp(block['time'], timezone(timedelta(hours=8)))
        month_key = dt.strftime("%Y_%m")
        if month_key not in grouped_data:
            grouped_data[month_key] = []
        grouped_data[month_key].append(block)

    for month_key, blocks in grouped_data.items():
        file_path = os.path.join(ARCHIVE_DIR, f"{month_key}.json")
        current_archive = []
        if os.path.exists(file_path):
            with open(file_path, "r") as f:
                try:
                    current_archive = json.load(f)
                except: pass
        
        existing_heights = {b['height'] for b in current_archive}
        for b in blocks:
            if b['height'] not in existing_heights:
                current_archive.append(b)
        
        current_archive.sort(key=lambda x: x['height'])
        with open(file_path, "w") as f:
            json.dump(current_archive, f, indent=None, separators=(',', ':'))

def main():
    now_bj = get_beijing_time()
    today_str = now_bj.strftime("%Y-%m-%d")

    if os.path.exists(LATEST_FILE):
        with open(LATEST_FILE, "r") as f:
            try: store = json.load(f)
            except: store = {}
    else:
        store = {}

    store.setdefault("last_height", get_latest_height() - 1)
    store.setdefault("history", [])
    store.setdefault("daily_max", {"value": 0, "txid": "N/A", "height": 0})
    
    # æ ¸å¿ƒæ–°å¢ï¼šåˆå§‹åŒ–æ¯æ—¥ç»Ÿè®¡æ•°æ®é¢æ¿
    store.setdefault("daily_stats", {}) 

    if store.get("last_date") != today_str:
        store["daily_max"] = {"value": 0, "txid": "N/A", "height": 0}
        store["last_date"] = today_str

    current_height = get_latest_height()
    last_height = store["last_height"]

    if current_height and current_height > last_height:
        print(f"ğŸš€ æ–°åŒºå—: {last_height + 1} -> {current_height}")
        new_blocks_buffer = []

        for h in range(last_height + 1, current_height + 1):
            time.sleep(1)
            try:
                info_url = f"https://blockchain.info/block-height/{h}?format=json"
                block_info = requests.get(info_url, timeout=20).json()
                block_hash = block_info['blocks'][0]['hash']
                
                # æ¥æ”¶æ–°å¢çš„å¥–åŠ±å’Œäº¤æ˜“é‡æ•°æ®
                top_3, block_ts, reward, volume = get_block_details(block_hash)
                
                # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´çš„æ—¥æœŸï¼Œç”¨äºæŒ‰æ—¥ç»Ÿè®¡
                block_date = datetime.fromtimestamp(block_ts, timezone(timedelta(hours=8))).strftime("%Y-%m-%d")
                
                # ç´¯åŠ æ¯æ—¥æ•°æ®
                if block_date not in store["daily_stats"]:
                    store["daily_stats"][block_date] = {"reward": 0, "volume": 0}
                store["daily_stats"][block_date]["reward"] += reward
                store["daily_stats"][block_date]["volume"] += volume

                if top_3 and top_3[0]['value'] > store["daily_max"]["value"]:
                    store["daily_max"] = {
                        "value": top_3[0]['value'],
                        "txid": top_3[0]['txid'],
                        "height": h
                    }

                block_data = {"height": h, "time": block_ts, "top_txs": top_3}
                store["history"].append(block_data)
                new_blocks_buffer.append(block_data)
                print(f"âœ… å¤„ç†åŒºå— {h} | å¥–åŠ±: {reward:.2f} | äº¤æ˜“é‡: {volume:.2f}")

            except Exception as e:
                print(f"é”™è¯¯ {h}: {e}")
                continue
        
        store["history"] = store["history"][-KEEP_LATEST_COUNT:] 
        store["last_height"] = current_height

        with open(LATEST_FILE, "w") as f:
            json.dump(store, f, indent=4)
        
        if new_blocks_buffer:
            save_to_archive(new_blocks_buffer)
            
        print("âœ… åŒæ­¥å®Œæˆï¼šçƒ­æ•°æ®ã€å†·æ¡£æ¡ˆã€æ¯æ—¥ç»Ÿè®¡å‡å·²æ›´æ–°")
    else:
        print("ğŸ˜´ æ— æ–°åŒºå—")

if __name__ == "__main__":
    main()
